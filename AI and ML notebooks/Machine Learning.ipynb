{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2715160e-6caa-4218-9993-0da4226d4f6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# 1. Aggregate FactStream to get Target Variable (Total Streams per Track)\n",
    "df_popularity = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        track_id, \n",
    "        COUNT(stream_id) as total_streams\n",
    "    FROM spotify_cata.gold.factstream\n",
    "    GROUP BY track_id\n",
    "\"\"\")\n",
    "\n",
    "# 2. Join with Dimensions to get Features\n",
    "df_features = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        t.track_id,\n",
    "        t.duration_sec,\n",
    "        t.release_date,\n",
    "        a.genre,\n",
    "        a.country as artist_country\n",
    "    FROM spotify_cata.gold.dimtrack t\n",
    "    JOIN spotify_cata.gold.dimartist a ON t.artist_id = a.artist_id\n",
    "\"\"\")\n",
    "\n",
    "# 3. Final Dataset\n",
    "df_full = df_features.join(df_popularity, \"track_id\", \"left\").fillna(0)\n",
    "\n",
    "# 4. Extract Year from Date\n",
    "df_full = df_full.withColumn(\"release_year\", F.year(\"release_date\"))\n",
    "\n",
    "# Convert to Pandas for Scikit-Learn (Limit to 100k rows if data is huge)\n",
    "pdf = df_full.limit(100000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67acb397-bcca-4249-ab91-d7d30af35e1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_country</th>\n",
       "      <th>total_streams</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>189</td>\n",
       "      <td>2023-07-16</td>\n",
       "      <td>Classical</td>\n",
       "      <td>Suriname</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226</td>\n",
       "      <td>102</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>244</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>307</td>\n",
       "      <td>2025-04-20</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>2</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>111</td>\n",
       "      <td>2022-06-03</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  duration_sec  ... total_streams release_year\n",
       "0       469           189  ...             3         2023\n",
       "1       226           102  ...             3         2024\n",
       "2       184           244  ...             1         2023\n",
       "3        51           307  ...             2         2025\n",
       "4       250           111  ...             2         2022\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c6acf1b-b495-43e4-8abc-bc2e7ad7268e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 15:54:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n2026/01/18 15:54:22 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n2026/01/18 15:54:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6534653465346535\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.65      1.00      0.79        66\n           1       0.00      0.00      0.00        35\n\n    accuracy                           0.65       101\n   macro avg       0.33      0.50      0.40       101\nweighted avg       0.43      0.65      0.52       101\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define Target\n",
    "threshold = pdf['total_streams'].median() \n",
    "pdf['is_hit'] = (pdf['total_streams'] > threshold).astype(int)\n",
    "pdf['is_hit'] = (pdf['total_streams'] > threshold).astype(int)\n",
    "\n",
    "# Define Features\n",
    "numeric_features = ['duration_sec', 'release_year']\n",
    "categorical_features = ['genre', 'artist_country']\n",
    "\n",
    "X = pdf[numeric_features + categorical_features]\n",
    "y = pdf['is_hit']\n",
    "X = pdf.drop(columns=['total_streams', 'is_hit', 'track_id'])\n",
    "\n",
    "# --- Build Preprocessing Pipeline ---\n",
    "# Numeric -> Scale\n",
    "# Categorical -> OneHotEncode \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# --- Train Model with MLflow ---\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Spotify_Metadata_Predictor\"):\n",
    "    \n",
    "    # Random Forest Pipeline\n",
    "    clf = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10))\n",
    "    ])\n",
    "    \n",
    "    # Train\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5091d1ec-df5e-4171-8641-aa02b88c0590",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6534653465346535\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.65      1.00      0.79        66\n           1       0.00      0.00      0.00        35\n\n    accuracy                           0.65       101\n   macro avg       0.33      0.50      0.40       101\nweighted avg       0.43      0.65      0.52       101\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/databricks/python/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "    print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31a29e1e-aafc-4ced-ae02-1cf468d448dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_hit\n0    329\n1    173\nName: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pdf['is_hit'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcd83ee8-c41a-4692-b385-cfbbf63ce6fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2f381407-ca7d-46e7-9aa8-11c91adf6283/lib/python3.12/site-packages (3.1.3)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.12/site-packages (from xgboost) (2.1.3)\nRequirement already satisfied: nvidia-nccl-cu12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2f381407-ca7d-46e7-9aa8-11c91adf6283/lib/python3.12/site-packages (from xgboost) (2.29.2)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.12/site-packages (from xgboost) (1.15.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01684d34-77c4-4924-a73f-4a0d302766c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6e8c705-aada-494f-a953-cf9ccbfea56a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 15:54:36 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '6873dada79d2415e9704b3e6327bd89c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n2026/01/18 15:54:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n2026/01/18 15:54:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n2026/01/18 15:54:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6336633663366337\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.69      0.79      0.74        66\n           1       0.46      0.34      0.39        35\n\n    accuracy                           0.63       101\n   macro avg       0.58      0.57      0.57       101\nweighted avg       0.61      0.63      0.62       101\n\n"
     ]
    }
   ],
   "source": [
    "clf2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(n_estimators=100, max_depth=10))\n",
    "])\n",
    "\n",
    "# Train\n",
    "clf2.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d929f1bd-804f-4925-9531-0c3391f52822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 15:54:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6336633663366337\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.69      0.79      0.74        66\n           1       0.46      0.34      0.39        35\n\n    accuracy                           0.63       101\n   macro avg       0.58      0.57      0.57       101\nweighted avg       0.61      0.63      0.62       101\n\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_pred = clf2.predict(X_test)\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14bbbfa0-8273-442b-9dc2-460d103df9a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Machine Learning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}